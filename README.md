# [뱅크샐러드] MLE Problem

## 01_EDA.ipynb
* text EDA 진행 (text len 설정을 위해)
* 글자단위, 띄어쓰기단위, BertTokenizer 단위로 진행함

## 02-01_Cnnbased_model.ipynb
* cnn + lstm 을 활용하여 모델 구조를 만들고 test를 진행함
* EDA시 title len에 대한 변수를 활용예정이였으나, 현재까지는 정확도에 좋은 영향을 주지 못함
  (향후 변수로 활용 가능 할 것이라고 판단됨)
* 결과 (loss:0.424, acc:0.918)


              precision    recall  f1-score   support

           0       0.92      0.91      0.91       912
           1       0.00      0.00      0.00         0
           2       0.88      0.93      0.91       258
           3       0.80      0.85      0.82       206
           4       0.96      0.94      0.95      1840
           5       0.85      0.87      0.86       223
           6       0.82      0.80      0.81        94
           7       0.83      0.83      0.83       272
           8       0.77      0.79      0.78        58
           9       0.91      0.82      0.86       120
          10       0.89      0.93      0.91       195
          11       0.98      1.00      0.99        90
          12       0.97      0.97      0.97       290
          13       0.97      0.99      0.98       144
          14       0.80      0.89      0.84        18
          15       0.73      0.80      0.76        10
          16       0.90      1.00      0.95        18

          accuracy                            0.92      4748
          macro avg       0.82      0.84      0.83      4748
          weighted avg    0.92      0.92      0.92      4748
    
    
    
## 02-02_bertbased_model.ipynb
* bert-base-multilingual-cased모델을 활용, 뒷단의 레이어를 일부 추가, 수정 후 test를 진행함
* 결과 (loss:0.410, acc:0.8901)

              precision    recall  f1-score   support

           0       0.83      0.92      0.87       816
           1       0.00      0.00      0.00         0
           2       0.82      0.92      0.87       244
           3       0.78      0.84      0.81       204
           4       0.96      0.88      0.92      1961
           5       0.91      0.91      0.91       227
           6       0.77      0.79      0.78        90
           7       0.83      0.78      0.80       289
           8       0.70      0.74      0.72        57
           9       0.84      0.84      0.84       109
          10       0.84      0.94      0.89       181
          11       0.99      0.93      0.96        98
          12       0.94      0.97      0.96       283
          13       0.98      0.97      0.98       149
          14       0.75      0.88      0.81        17
          15       0.36      1.00      0.53         4
          16       0.90      0.95      0.92        19

          accuracy                            0.89      4748
          macro avg       0.78      0.84      0.80      4748
          weighted avg    0.90      0.89      0.89      4748
          
## 최종 모델 선정 및 결과
### 02-01_Cnnbased_model 선정
#### 속도 및 안내된 평가지표기준에 따라 02-01_Cnnbased_model 모델을 선정함
##### (./MLE Problem/model_result/model_2021-02-27-0816_모델 설명.txt)


